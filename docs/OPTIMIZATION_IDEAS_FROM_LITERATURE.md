# 枪声检测优化思路（来自文献与业界）

根据近期文献和业界做法整理的、可落地的优化方向，便于开阔思路、选方向做实验。

---

## 一、音频侧：降低误报、提升 Precision

### 1. 后处理参数自动优化（强烈推荐）

- **来源**：DCASE 声学事件检测、[Improving Post-Processing of Audio Event Detectors Using Reinforcement Learning (arXiv:2208.09201)](https://arxiv.org/abs/2208.09201)
- **要点**：  
  分类/检测后的「阈值 + 平滑（如中值滤波）」等后处理参数，对 F1 影响很大；用**强化学习**联合搜索「每类阈值 + 滤波核大小」等，可比手调提升约 **4–5%** 的 macro F1。
- **对你项目的启发**：  
  - 你已有 `--sweep-threshold`，可扩展为对「置信度阈值 + NMS 窗口 + 聚类窗口」做**网格搜索或简单自动搜索**，以 F1（或 P/R 折中）为目标选参数。  
  - 不必上 RL，先用网格/贝叶斯优化即可；有标注时再考虑 RL 自动调后处理。

### 2. 枪声相关特征（MFCC / 谱 + onset）

- **来源**：枪声识别/分类文献（如 MFCC + 谱特征）、Nature/Scientific Reports 等。
- **要点**：  
  - **MFCC** 在枪声检测中常用，干净场景约 95% 检测率，含噪约 85%。  
  - 常与 **LPC、谱质心、onset 特性**等联合使用；**功率谱密度 + MFCC** 可提升噪声鲁棒性。
- **对你项目的启发**：  
  - 你已有 spectral flux、多频段能量比、attack 等，可考虑**增加 MFCC 或 LFCC 的若干维**作为额外特征，送入现有打分或 LogReg，看是否减误报。  
  - 若已有「误报样本」，可对比真枪声与误报在 MFCC/谱上的差异，做简单规则或特征加权。

### 3. 类别相关后处理（class-dependent）

- **来源**：DCASE 后处理、SED 评测框架。  
- **要点**：  
  **按类别/按场景使用不同阈值和滤波参数**（class-dependent parametric methods）常优于单一全局阈值，F-score 提升明显（文献中有约 32% vs 22% 的对比）。
- **对你项目的启发**：  
  - 若将来区分「枪声 / 击掌 / 关门」等多类，可对「枪声」单独设更严的阈值和 NMS 窗口。  
  - 当前单类也可做：**高置信度用松窗口、低置信度用严窗口**，等价于「类别/置信度相关」后处理。

---

## 二、运动/视频侧：提高检出、更稳

### 4. 自适应帧差与自适应阈值

- **来源**：帧差法运动检测、自适应阈值文献（如 MDPI Electronics、IEEE）。  
- **要点**：  
  - **固定阈值**易在光照/场景变化下误检或漏检。  
  - **自适应阈值**：根据当前帧或局部统计（如均值+方差、分位数）动态设阈值。  
  - **自适应帧间隔**：根据运动速度调整参与帧差的帧数（快动作用少帧、慢动作用多帧），可同时照顾快速后坐与慢速抖动。
- **对你项目的启发**：  
  - 运动检测当前若用固定阈值，可改为**滑动窗口内中位数 + k×MAD** 或**分位数阈值**，减少因某段画面整体变亮/变抖导致的误峰。  
  - 可尝试**多尺度帧差**：相邻帧差（敏感于快动）+ 隔 N 帧差（敏感于慢动），两路峰做融合或取并。

### 5. 后坐力与相机运动特性

- **来源**：枪械后坐力高速视频分析、可穿戴传感器枪击识别（如 PLOS One 99.4% 准确率）。  
- **要点**：  
  - 真枪击在**手腕/相机**上会有**短时冲击型加速度/运动**，与一般走动、抖动在**波形形状、持续时间**上不同。  
  - 高速视频（如 240fps）可看清后坐与枪口运动；30fps 下更依赖「短窗内运动包络形状」而非单帧。
- **对你项目的启发**：  
  - 在运动时序上做**短窗特征**：例如枪声时刻前后各 0.05s 的「峰度、上升沿斜率、短时能量」等，区分「瞬时冲击」与「持续晃动」。  
  - 你已有 `motion_ratio`（post/pre），可再加「峰宽度」「上升时间」等，用规则或小分类器筛掉非冲击类运动。

---

## 三、音视频融合（开阔思路）

### 6. 早融合 vs 晚融合

- **来源**：视听融合综述、DCASE SELD、两阶段融合策略。  
- **要点**：  
  - **早融合**：在特征层合并音视频，再进一个网络，利于细粒度对齐。  
  - **晚融合**：各模态先独立检测，再在决策层合并（你当前「音频检测 + 运动确认」就是晚融合）。  
  - **两阶段**：先早融合特征做一次预测，再与单模态决策做晚融合，综合两者优势。
- **对你项目的启发**：  
  - 当前是**晚融合**（音频主检测 + 运动做验证），已合理。  
  - 若以后上深度学习：可考虑**在帧级或片段级**用简单早融合（如音频谱图 + 运动曲线拼成二维输入）训一个小网络，再与现有规则晚融合结合。

### 7. 教师–学生与跨模态学习

- **来源**：DCASE、低资源视听事件检测。  
- **要点**：  
  用「音频教师」指导「音视频学生」、或跨模态数据增强（如 Audio Channel Swapping + Video Pixel Swapping），在低资源下提升鲁棒性。
- **对你项目的启发**：  
  - 若只有少量「带 ref 的枪声视频」：可先用**纯音频**在更多数据上训一个检测/分类器，再在视频上做**知识蒸馏或伪标签**，让「音频+运动」模型学到更稳的决策边界。  
  - 数据增强：对音频做加噪、时移、通道交换；对视频做裁剪、亮度抖动，再对齐到同一枪声时刻。

---

## 四、工程与评测

### 8. 多阈值评测（PSDS / ROC）

- **来源**：DCASE、Polyphonic Sound Detection Score (PSDS)。  
- **要点**：  
  不单看一个阈值的 P/R/F1，而是看**一整条 ROC 或不同阈值下的表现**，用 PSDS 等指标评估，再选「应用最需要的操作点」。
- **对你项目的启发**：  
  - 你已有 `--sweep-threshold`，可把结果画成 **Precision–Recall 曲线**或 **阈值–F1 曲线**，便于选阈值和比较不同配置。  
  - 可固定 ref，对不同 `min_confidence_threshold`、不同 NMS 窗口做 sweep，存成小表格或 CSV，方便对比。

### 9. 事件级 vs 片段级

- **来源**：SED 评测（segment-based vs event-based）。  
- **要点**：  
  - **片段级**：按固定时长切段，每段一个标签。  
  - **事件级**：按「事件起点/终点 + 容忍度」匹配，更贴近「数枪声」场景。
- **对你项目的启发**：  
  - 你当前用 ±0.04s 匹配 GT，本质是**事件级**，合理。  
  - 若要做「每段是否有枪声」的 segment 指标，可再补一段「按固定窗切段 + 段内是否有匹配事件」的评测脚本。

---

## 五、可优先尝试的 3 件事（不依赖大模型）

1. **运动检测**：把固定阈值改成**滑动窗口自适应阈值**（如中位数 + k×MAD），并试**多尺度帧差**（相邻帧 + 隔 2 帧），看运动检出数是否更稳、更多真枪被覆盖。  
2. **音频后处理**：在现有 `--sweep-threshold` 基础上，对 **NMS 窗口、聚类窗口、min_confidence** 做**联合网格搜索**，以 F1 或你指定的 P/R 折中为目标选参。  
3. **运动形状特征**：在枪声时刻前后取短窗运动曲线，算**上升时间、峰宽、对称性**等，与 `motion_ratio` 一起筛掉「非冲击」运动，减少运动误报、提高「运动确认」的可信度。

---

## 参考文献与链接（可进一步阅读）

- Post-processing + RL: [arXiv:2208.09201](https://arxiv.org/abs/2208.09201)  
- 枪声 MFCC/谱特征：Nature Scientific Reports、Springer 相关章节  
- 帧差与自适应阈值：MDPI Electronics, IEEE 帧差/混合运动检测  
- 视听融合：DCASE 2023/2024、两阶段融合策略  
- 后坐力/传感器：PLOS One 手腕传感器枪击识别、高速视频后坐分析  

如需在现有代码里实现「自适应运动阈值」或「后处理参数网格搜索」的具体改法，可以指定文件（如 `shot_motion.py` / `main.py`）和期望接口，我可以按你项目结构写出补丁级修改建议。
